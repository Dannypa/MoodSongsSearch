{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying manual tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras, keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # coding: utf-8\n",
    "# import sys\n",
    "# import codecs\n",
    "# import numpy as np\n",
    "# from keras_bert import load_trained_model_from_checkpoint\n",
    "# import bert.tokenization as tokenization\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_json = {\n",
    "#     \"bert\": 'C:\\\\Users\\dannu\\\\bert-base',\n",
    "# }\n",
    "# config_json['bert_config'] = os.path.join(config_json['bert'], 'bert_config.json')\n",
    "# config_json['checkpoint'] = os.path.join(config_json['bert'], 'bert_model.ckpt')\n",
    "# config_json['vocab'] = os.path.join(config_json['bert'], 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tokenization.FullTokenizer(vocab_file=config_json['vocab'], do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer.tokenize(\"\"\"\n",
    "# The sun is nearly gone\n",
    "# The lights are turning on\n",
    "# A silver shine that stretches to the sea\n",
    "# We've stumbled on a view\n",
    "# That's tailor-made for two\n",
    "# What a shame those two are you and me\n",
    "# Some other girl and guy\n",
    "# Would love this swirling sky\n",
    "# But there's only you and I\n",
    "# And we've got no shot\n",
    "# This could never be\n",
    "# You're not the type for me (really?)\n",
    "# And there's not a spark in sight\n",
    "# What a waste of a lovely night\n",
    "# You say there's nothing here?\n",
    "# Well, let's make something clear\n",
    "# I think I'll be the one to make that call (but you'll call?)\n",
    "# And though you looked so cute\n",
    "# In your polyester suit (it's wool)\n",
    "# You're right, I'd never fall for you at all\n",
    "# And maybe this appeals\n",
    "# To someone not in heels\n",
    "# Or to any girl who feels\n",
    "# There's some chance for romance\n",
    "# But, I'm frankly feeling nothing\n",
    "# Is that so?\n",
    "# Or it could be less than nothing\n",
    "# Good to know, so you agree?\n",
    "# That's right\n",
    "# What a waste of a lovely night\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_input = tokenizer.convert_tokens_to_ids(tokens)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_tokens_to_ids([\"king\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_tokens_to_ids([\"queen\"])[0] - tokenizer.convert_tokens_to_ids(\"woman\") [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually, i'd rather try old thing, but a better version of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnames = [\n",
    "    \"all-MiniLM-L12-v2\",\n",
    "    \"distiluse-base-multilingual-cased-v2\",\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"all-distilroberta-v1\",\n",
    "    \"all-mpnet-base-v2\",\n",
    "    \"multi-qa-mpnet-base-dot-v1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import config\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Song:\n",
    "    lyrics: np.array\n",
    "    name: str\n",
    "    artist: str\n",
    "    meta: list\n",
    "\n",
    "\n",
    "def dict_to_list_fixed(d):\n",
    "    tmp = list(d.items())\n",
    "    tmp.sort()\n",
    "    return [i[1] for i in tmp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:28<00:00,  4.32it/s]\n",
      "100%|██████████| 125/125 [00:49<00:00,  2.53it/s]\n",
      "100%|██████████| 125/125 [00:58<00:00,  2.12it/s]\n",
      "100%|██████████| 125/125 [00:59<00:00,  2.12it/s]\n",
      "100%|██████████| 125/125 [00:57<00:00,  2.18it/s]\n",
      "100%|██████████| 125/125 [00:57<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "remake = False\n",
    "if remake:\n",
    "    data = []\n",
    "    for name in tnames:\n",
    "        part = []\n",
    "        dir = config.SONG_DATA_PATH + \"-\" + name\n",
    "        for file in tqdm.tqdm(os.listdir(dir)):\n",
    "            with open(os.path.join(dir, file), 'r') as f:\n",
    "                cur = json.load(f)\n",
    "                for el in cur:\n",
    "                    part.append(Song(np.array(el['lyrics']), el['song'], el['artist'], el['meta']))\n",
    "        data.append(part)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124132"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [\n",
    "    np.array([el.lyrics for el in data[i]]) for i in range(len(data))\n",
    "]\n",
    "meta = [\n",
    "    np.array([el.meta for el in data[i]]) for i in range(len(data))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    list(zip(lyrics[i], meta[i])) for i in range(len(data)) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(len(dataset[i])):\n",
    "        dataset[i][j] = list(dataset[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6773615479469299\n",
      "0.30614569783210754\n",
      "2.6710147857666016\n",
      "0.2917146384716034\n",
      "0.23229560256004333\n",
      "1.5698649883270264\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    print(lyrics[i].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding downloaded data (no need in that now cause i've already encoded everything in a separate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5674/5674 [2:10:49<00:00,  1.38s/it]  \n"
     ]
    }
   ],
   "source": [
    "# import tqdm\n",
    "# from threading import Thread\n",
    "\n",
    "# remake = False\n",
    "\n",
    "# if remake:\n",
    "#     def fill_encoded(index):\n",
    "#         encoded_data[index] = (transformer.encode(data[index][0]), data[index][1])\n",
    "\n",
    "#     step = 2\n",
    "#     for i in tqdm.trange(0, len(data), step):\n",
    "#         threads = [Thread(target=fill_encoded, args=(i + j,)) for j in range(min(step, len(data) - i))]\n",
    "#         for t in threads:\n",
    "#             t.start()\n",
    "#         for t in threads:\n",
    "#             t.join()\n",
    "#         # break\n",
    "#         # encoded_data[i] = (transformer.encode(data[i][0]), data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['danceability', 'energy', 'key', 'loudness', 'mode', 'valence', 'tempo'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoded_data[0][1].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving encoded data (no need in that now cause i've already encoded everything in a separate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"all-mpnet-base-v2-data-new\"\n",
    "# remake = False\n",
    "# keys = ['danceability', 'energy', 'key', 'loudness', 'mode', 'valence', 'tempo']\n",
    "# if remake:\n",
    "#     cur = []\n",
    "#     index = 0\n",
    "#     for el in encoded_data:\n",
    "#         cur.append({\"lyrics\": [x.item() for x in el[0]], \"meta\": [el[1][k] for k in keys]})\n",
    "#         # print(cur)\n",
    "#         # break\n",
    "#         if len(cur) >= 1000:\n",
    "#             filename = os.path.join(DATA_DIR, f\"data-{index}.json\")\n",
    "#             index += 1\n",
    "#             with open(filename, 'w') as f:\n",
    "#                 json.dump(cur, f)\n",
    "#             cur = []\n",
    "#     filename = os.path.join(DATA_DIR, f\"data-{index}.json\")\n",
    "#     index += 1\n",
    "#     with open(filename, 'w') as f:\n",
    "#         json.dump(cur, f)\n",
    "#     cur = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# DATA_DIR = \"all-mpnet-base-v2-data\"\n",
    "# lyrics_max_val = 3.0483362674713135\n",
    "# meta_max_val = [torch.tensor(0.9880), torch.tensor(1.), torch.tensor(11.), torch.tensor(60.), torch.tensor(1.), torch.tensor(0.9970), torch.tensor(220.1690)]\n",
    "    \n",
    "# vecs = []\n",
    "# for file in os.listdir(DATA_DIR):\n",
    "#     if file.endswith('.json'):\n",
    "#         filename = os.path.join(DATA_DIR, file)\n",
    "#         with open(filename, 'r') as f:\n",
    "#             cur = json.load(f)\n",
    "#             for el in cur:\n",
    "#                 meta = el['meta']\n",
    "#                 for j in range(len(meta)):\n",
    "#                     meta[j] /= meta_max_val[j]\n",
    "#                 lyrics = el['lyrics']\n",
    "#                 for j in range(len(lyrics)):\n",
    "#                     lyrics[j] /= lyrics_max_val\n",
    "#                 vecs.append((np.array(lyrics, dtype=np.float32), np.array(meta, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rn scaling uses hardcoded values because the calculations of maximum values took to much time; it is the version that can be used to recalc values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6773615479469299, 0.30614569783210754, 2.6710147857666016, 0.3280427157878876, 0.23734550178050995, 1.5698649883270264]\n",
      "[  0.988   1.     11.     60.      1.    243.034   0.993]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124132/124132 [00:01<00:00, 79530.22it/s]\n",
      "100%|██████████| 124132/124132 [00:02<00:00, 53754.95it/s]\n",
      "100%|██████████| 124132/124132 [00:01<00:00, 116258.67it/s]\n",
      "100%|██████████| 124132/124132 [00:02<00:00, 51094.13it/s]\n",
      "100%|██████████| 124132/124132 [00:01<00:00, 110559.94it/s]\n",
      "100%|██████████| 124132/124132 [00:01<00:00, 117453.09it/s]\n"
     ]
    }
   ],
   "source": [
    "def scale_data():\n",
    "    global dataset, data\n",
    "    n = len(dataset)\n",
    "    # may be scaling is not needed.\n",
    "    first_time = True\n",
    "    if first_time:\n",
    "        lyrics_max_val = [\n",
    "            np.abs(lyrics[i]).max() for i in range(len(data))\n",
    "        ]\n",
    "        meta_max_val = np.abs(meta[0]).max(axis=0)\n",
    "\n",
    "    print(lyrics_max_val)\n",
    "    print(meta_max_val)\n",
    "\n",
    "\n",
    "    first_time = True\n",
    "    if first_time:\n",
    "        # c = input(\"continue?(y/n)>>\")\n",
    "        c = 'y'\n",
    "        if c.lower() == 'y':\n",
    "            for i in range(len(data)):\n",
    "                for j in tqdm.trange(len(dataset[i])):\n",
    "                    dataset[i][j][0] /= lyrics_max_val[i]\n",
    "                    for k in range(7):\n",
    "                        dataset[i][j][1][k] /= meta_max_val[k]\n",
    "    # print(dataset[1])\n",
    "scale_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating data into np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# vecs = [(np.array([x.item() for x in el[0]], dtype=np.float32), np.array([el[1][k] for k in keys], dtype=np.float32)) for el in encoded_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vecs[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting data into dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "train_loader, test_loader = [], []\n",
    "def split_data():\n",
    "    global train_set, test_loader, test_set, train_loader\n",
    "    for i in range(len(data)):\n",
    "        n = len(dataset[i])\n",
    "        train_size = int(n * .8)\n",
    "        train_set = dataset[i][:train_size]\n",
    "        test_set = dataset[i][train_size:]\n",
    "        # len(train_set), len(test_set)\n",
    "        train_loader.append(torch.utils.data.DataLoader(train_set, batch_size=config.BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True))\n",
    "        test_loader.append(torch.utils.data.DataLoader(test_set, batch_size=config.BATCH_SIZE, shuffle=False))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import config as config\n",
    "import torch.nn as nn\n",
    "import time\n",
    "def train_loop(model, criterion, optimizer, train_loader, n):\n",
    "    loss_avg = AverageMeter()\n",
    "    acc_stat = AverageMeter()\n",
    "    start_time = time.time()\n",
    "    for embeddings, targets in train_loader:\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        embeddings = embeddings.to(DEVICE).to(torch.float32)\n",
    "        targets = targets.to(DEVICE).to(torch.float32)\n",
    "        # print(embeddings.shape, targets.shape)\n",
    "        output = model(embeddings)\n",
    "        loss = criterion(output, targets)\n",
    "        loss_avg.update(loss.item(), 1)\n",
    "\n",
    "        output2 = output.softmax(dim=1)\n",
    "        output2 = output2.cpu().detach().numpy()\n",
    "\n",
    "        acc = np.linalg.norm(targets.cpu() - output2)\n",
    "\n",
    "        acc_stat.update(acc, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "    print(f\"{n} epoch, Loss: {loss_avg.avg:.5f}, acc: {acc_stat.avg:.4f}, LR: {lr:.7f}, Time for cycle: {(time.time() - start_time):.2f} sec\")\n",
    "    return loss_avg.avg\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def model_load(preTrained=False, model=None, checkpoint_path=\"\"):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    if preTrained:\n",
    "        \"\"\"Loading model\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE )\n",
    "        model.load_state_dict(     checkpoint['model'])\n",
    "        model=model.to(DEVICE)\n",
    "        # optimizer.load_state_dict( checkpoint['optimizer']) # i want to change lr\n",
    "        epoch =                    checkpoint['epoch']\n",
    "        score =                    checkpoint['score']\n",
    "        return model, optimizer, criterion, epoch, score\n",
    "    else:\n",
    "        return model.to(DEVICE), optimizer, criterion, 0, 0\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, epoch, score, path):\n",
    "    checkpoint={\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'score': score\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "def Train_log(score, path):\n",
    "    arr=np.array([score])\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            arr = np.load(f)\n",
    "        arr = np.append(arr, score)\n",
    "    with open(path, 'wb') as f:\n",
    "        np.save(f, arr)\n",
    "\n",
    "\n",
    "def train(second_time, model, name, index):\n",
    "    # chp = config.ROOT + '/' + config.CHECKPOINT_PATH[0] + name # no need in root + ... later\n",
    "    chp = config.CHECKPOINT_PATH + name\n",
    "    model, optimizer, criterion, epoch, score = model_load(second_time, model, chp)\n",
    "    print(\"Model loaded\")\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    model=model.to(DEVICE)\n",
    "    for e in range(100):\n",
    "        score = train_loop(model, criterion, optimizer, train_loader[i], e)\n",
    "        save_model(model, optimizer, e, score, chp)\n",
    "        Train_log(score, config.TRAIN_LOG)\n",
    "        print(\"Data saved \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Model loaded\n",
      "0 epoch, Loss: 0.08058, acc: 28.1156, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "1 epoch, Loss: 0.06585, acc: 28.0425, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "2 epoch, Loss: 0.06505, acc: 28.0286, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "3 epoch, Loss: 0.06441, acc: 28.0224, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "4 epoch, Loss: 0.06383, acc: 28.0128, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "5 epoch, Loss: 0.06316, acc: 28.0021, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "6 epoch, Loss: 0.06219, acc: 27.9886, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "7 epoch, Loss: 0.06116, acc: 27.9710, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "8 epoch, Loss: 0.06008, acc: 27.9527, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "9 epoch, Loss: 0.05860, acc: 27.9293, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "10 epoch, Loss: 0.05720, acc: 27.9063, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "11 epoch, Loss: 0.05557, acc: 27.8826, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "12 epoch, Loss: 0.05411, acc: 27.8567, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "13 epoch, Loss: 0.05262, acc: 27.8358, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "14 epoch, Loss: 0.05136, acc: 27.8107, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "15 epoch, Loss: 0.04983, acc: 27.7897, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "16 epoch, Loss: 0.04841, acc: 27.7665, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "17 epoch, Loss: 0.04706, acc: 27.7442, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "18 epoch, Loss: 0.04573, acc: 27.7248, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "19 epoch, Loss: 0.04471, acc: 27.7080, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "20 epoch, Loss: 0.04368, acc: 27.6908, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "21 epoch, Loss: 0.04234, acc: 27.6717, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "22 epoch, Loss: 0.04124, acc: 27.6559, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "23 epoch, Loss: 0.04016, acc: 27.6391, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "24 epoch, Loss: 0.03936, acc: 27.6264, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "25 epoch, Loss: 0.03869, acc: 27.6154, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "26 epoch, Loss: 0.03780, acc: 27.5995, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "27 epoch, Loss: 0.03668, acc: 27.5868, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "28 epoch, Loss: 0.03626, acc: 27.5783, LR: 0.0010000, Time for cycle: 1.79 sec\n",
      "Data saved \n",
      "\n",
      "29 epoch, Loss: 0.03567, acc: 27.5679, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "30 epoch, Loss: 0.03520, acc: 27.5622, LR: 0.0010000, Time for cycle: 1.79 sec\n",
      "Data saved \n",
      "\n",
      "31 epoch, Loss: 0.03472, acc: 27.5555, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "32 epoch, Loss: 0.03410, acc: 27.5450, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "33 epoch, Loss: 0.03353, acc: 27.5375, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "34 epoch, Loss: 0.03297, acc: 27.5303, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "35 epoch, Loss: 0.03286, acc: 27.5262, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "36 epoch, Loss: 0.03220, acc: 27.5180, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "37 epoch, Loss: 0.03186, acc: 27.5124, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "38 epoch, Loss: 0.03133, acc: 27.5073, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "39 epoch, Loss: 0.03083, acc: 27.4970, LR: 0.0010000, Time for cycle: 1.79 sec\n",
      "Data saved \n",
      "\n",
      "40 epoch, Loss: 0.03073, acc: 27.4977, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "41 epoch, Loss: 0.03031, acc: 27.4899, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "42 epoch, Loss: 0.02966, acc: 27.4815, LR: 0.0010000, Time for cycle: 1.79 sec\n",
      "Data saved \n",
      "\n",
      "43 epoch, Loss: 0.02938, acc: 27.4779, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "44 epoch, Loss: 0.02881, acc: 27.4683, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "45 epoch, Loss: 0.02850, acc: 27.4637, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "46 epoch, Loss: 0.02832, acc: 27.4614, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "47 epoch, Loss: 0.02803, acc: 27.4580, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "48 epoch, Loss: 0.02769, acc: 27.4536, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "49 epoch, Loss: 0.02740, acc: 27.4479, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "50 epoch, Loss: 0.02755, acc: 27.4520, LR: 0.0010000, Time for cycle: 1.64 sec\n",
      "Data saved \n",
      "\n",
      "51 epoch, Loss: 0.02699, acc: 27.4417, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "52 epoch, Loss: 0.02656, acc: 27.4374, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "53 epoch, Loss: 0.02642, acc: 27.4319, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "54 epoch, Loss: 0.02621, acc: 27.4297, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "55 epoch, Loss: 0.02606, acc: 27.4287, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "56 epoch, Loss: 0.02573, acc: 27.4251, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "57 epoch, Loss: 0.02548, acc: 27.4190, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "58 epoch, Loss: 0.02526, acc: 27.4176, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "59 epoch, Loss: 0.02550, acc: 27.4205, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "60 epoch, Loss: 0.02503, acc: 27.4143, LR: 0.0010000, Time for cycle: 1.66 sec\n",
      "Data saved \n",
      "\n",
      "61 epoch, Loss: 0.02490, acc: 27.4120, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "62 epoch, Loss: 0.02490, acc: 27.4103, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "63 epoch, Loss: 0.02436, acc: 27.4053, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "64 epoch, Loss: 0.02402, acc: 27.3987, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "65 epoch, Loss: 0.02385, acc: 27.3954, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "66 epoch, Loss: 0.02356, acc: 27.3921, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "67 epoch, Loss: 0.02343, acc: 27.3908, LR: 0.0010000, Time for cycle: 1.65 sec\n",
      "Data saved \n",
      "\n",
      "68 epoch, Loss: 0.02410, acc: 27.4001, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "69 epoch, Loss: 0.02339, acc: 27.3904, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "70 epoch, Loss: 0.02308, acc: 27.3859, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "71 epoch, Loss: 0.02277, acc: 27.3796, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "72 epoch, Loss: 0.02300, acc: 27.3851, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "73 epoch, Loss: 0.02278, acc: 27.3816, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "74 epoch, Loss: 0.02250, acc: 27.3776, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "75 epoch, Loss: 0.02251, acc: 27.3764, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "76 epoch, Loss: 0.02245, acc: 27.3756, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "77 epoch, Loss: 0.02254, acc: 27.3785, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "78 epoch, Loss: 0.02209, acc: 27.3699, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "79 epoch, Loss: 0.02207, acc: 27.3698, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "80 epoch, Loss: 0.02213, acc: 27.3711, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "81 epoch, Loss: 0.02250, acc: 27.3787, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "82 epoch, Loss: 0.02153, acc: 27.3605, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "83 epoch, Loss: 0.02112, acc: 27.3564, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "84 epoch, Loss: 0.02086, acc: 27.3528, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "85 epoch, Loss: 0.02098, acc: 27.3539, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "86 epoch, Loss: 0.02176, acc: 27.3663, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "87 epoch, Loss: 0.02137, acc: 27.3622, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "88 epoch, Loss: 0.02129, acc: 27.3589, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "89 epoch, Loss: 0.02078, acc: 27.3518, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "90 epoch, Loss: 0.02099, acc: 27.3559, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "91 epoch, Loss: 0.02072, acc: 27.3486, LR: 0.0010000, Time for cycle: 1.65 sec\n",
      "Data saved \n",
      "\n",
      "92 epoch, Loss: 0.02059, acc: 27.3498, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "93 epoch, Loss: 0.02050, acc: 27.3476, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "94 epoch, Loss: 0.02074, acc: 27.3483, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "95 epoch, Loss: 0.02042, acc: 27.3465, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "96 epoch, Loss: 0.02002, acc: 27.3399, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "97 epoch, Loss: 0.02027, acc: 27.3443, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "98 epoch, Loss: 0.02011, acc: 27.3419, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "99 epoch, Loss: 0.02012, acc: 27.3427, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "512\n",
      "Model loaded\n",
      "0 epoch, Loss: 0.07772, acc: 28.0937, LR: 0.0010000, Time for cycle: 6.06 sec\n",
      "Data saved \n",
      "\n",
      "1 epoch, Loss: 0.06626, acc: 28.0416, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "2 epoch, Loss: 0.06534, acc: 28.0308, LR: 0.0010000, Time for cycle: 1.89 sec\n",
      "Data saved \n",
      "\n",
      "3 epoch, Loss: 0.06460, acc: 28.0220, LR: 0.0010000, Time for cycle: 1.95 sec\n",
      "Data saved \n",
      "\n",
      "4 epoch, Loss: 0.06384, acc: 28.0109, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "5 epoch, Loss: 0.06276, acc: 27.9903, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "6 epoch, Loss: 0.06152, acc: 27.9682, LR: 0.0010000, Time for cycle: 1.97 sec\n",
      "Data saved \n",
      "\n",
      "7 epoch, Loss: 0.05982, acc: 27.9447, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "8 epoch, Loss: 0.05811, acc: 27.9155, LR: 0.0010000, Time for cycle: 1.92 sec\n",
      "Data saved \n",
      "\n",
      "9 epoch, Loss: 0.05619, acc: 27.8835, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "10 epoch, Loss: 0.05426, acc: 27.8523, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "11 epoch, Loss: 0.05223, acc: 27.8182, LR: 0.0010000, Time for cycle: 1.92 sec\n",
      "Data saved \n",
      "\n",
      "12 epoch, Loss: 0.05033, acc: 27.7895, LR: 0.0010000, Time for cycle: 1.99 sec\n",
      "Data saved \n",
      "\n",
      "13 epoch, Loss: 0.04839, acc: 27.7601, LR: 0.0010000, Time for cycle: 1.89 sec\n",
      "Data saved \n",
      "\n",
      "14 epoch, Loss: 0.04702, acc: 27.7366, LR: 0.0010000, Time for cycle: 2.39 sec\n",
      "Data saved \n",
      "\n",
      "15 epoch, Loss: 0.04500, acc: 27.7094, LR: 0.0010000, Time for cycle: 1.94 sec\n",
      "Data saved \n",
      "\n",
      "16 epoch, Loss: 0.04335, acc: 27.6834, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "17 epoch, Loss: 0.04236, acc: 27.6657, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "18 epoch, Loss: 0.04087, acc: 27.6447, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "19 epoch, Loss: 0.03974, acc: 27.6296, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "20 epoch, Loss: 0.03856, acc: 27.6117, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "21 epoch, Loss: 0.03781, acc: 27.5983, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "22 epoch, Loss: 0.03678, acc: 27.5834, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "23 epoch, Loss: 0.03585, acc: 27.5716, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "24 epoch, Loss: 0.03526, acc: 27.5641, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "25 epoch, Loss: 0.03433, acc: 27.5472, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "26 epoch, Loss: 0.03353, acc: 27.5374, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "27 epoch, Loss: 0.03309, acc: 27.5303, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "28 epoch, Loss: 0.03237, acc: 27.5194, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "29 epoch, Loss: 0.03159, acc: 27.5093, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "30 epoch, Loss: 0.03140, acc: 27.5049, LR: 0.0010000, Time for cycle: 1.92 sec\n",
      "Data saved \n",
      "\n",
      "31 epoch, Loss: 0.03049, acc: 27.4956, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "32 epoch, Loss: 0.03007, acc: 27.4876, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "33 epoch, Loss: 0.02945, acc: 27.4795, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "34 epoch, Loss: 0.02859, acc: 27.4669, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "35 epoch, Loss: 0.02843, acc: 27.4654, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "36 epoch, Loss: 0.02779, acc: 27.4570, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "37 epoch, Loss: 0.02734, acc: 27.4503, LR: 0.0010000, Time for cycle: 1.94 sec\n",
      "Data saved \n",
      "\n",
      "38 epoch, Loss: 0.02691, acc: 27.4432, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "39 epoch, Loss: 0.02647, acc: 27.4365, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "40 epoch, Loss: 0.02608, acc: 27.4328, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "41 epoch, Loss: 0.02596, acc: 27.4309, LR: 0.0010000, Time for cycle: 1.99 sec\n",
      "Data saved \n",
      "\n",
      "42 epoch, Loss: 0.02539, acc: 27.4219, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "43 epoch, Loss: 0.02514, acc: 27.4175, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "44 epoch, Loss: 0.02498, acc: 27.4170, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "45 epoch, Loss: 0.02465, acc: 27.4120, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "46 epoch, Loss: 0.02436, acc: 27.4050, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "47 epoch, Loss: 0.02406, acc: 27.4031, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "48 epoch, Loss: 0.02369, acc: 27.3972, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "49 epoch, Loss: 0.02324, acc: 27.3895, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "50 epoch, Loss: 0.02324, acc: 27.3891, LR: 0.0010000, Time for cycle: 1.92 sec\n",
      "Data saved \n",
      "\n",
      "51 epoch, Loss: 0.02315, acc: 27.3909, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "52 epoch, Loss: 0.02288, acc: 27.3849, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "53 epoch, Loss: 0.02247, acc: 27.3794, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "54 epoch, Loss: 0.02244, acc: 27.3775, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "55 epoch, Loss: 0.02220, acc: 27.3754, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "56 epoch, Loss: 0.02183, acc: 27.3706, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "57 epoch, Loss: 0.02196, acc: 27.3716, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "58 epoch, Loss: 0.02172, acc: 27.3678, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "59 epoch, Loss: 0.02147, acc: 27.3617, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "60 epoch, Loss: 0.02123, acc: 27.3608, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "61 epoch, Loss: 0.02095, acc: 27.3572, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "62 epoch, Loss: 0.02120, acc: 27.3576, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "63 epoch, Loss: 0.02093, acc: 27.3549, LR: 0.0010000, Time for cycle: 1.92 sec\n",
      "Data saved \n",
      "\n",
      "64 epoch, Loss: 0.02083, acc: 27.3543, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "65 epoch, Loss: 0.02076, acc: 27.3520, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "66 epoch, Loss: 0.02072, acc: 27.3506, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "67 epoch, Loss: 0.02018, acc: 27.3443, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "68 epoch, Loss: 0.02007, acc: 27.3436, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "69 epoch, Loss: 0.01994, acc: 27.3401, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "70 epoch, Loss: 0.01990, acc: 27.3424, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "71 epoch, Loss: 0.01961, acc: 27.3340, LR: 0.0010000, Time for cycle: 1.79 sec\n",
      "Data saved \n",
      "\n",
      "72 epoch, Loss: 0.01945, acc: 27.3333, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "73 epoch, Loss: 0.01940, acc: 27.3302, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "74 epoch, Loss: 0.01945, acc: 27.3328, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "75 epoch, Loss: 0.01973, acc: 27.3383, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "76 epoch, Loss: 0.01944, acc: 27.3314, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "77 epoch, Loss: 0.01886, acc: 27.3230, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "78 epoch, Loss: 0.01873, acc: 27.3203, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "79 epoch, Loss: 0.01893, acc: 27.3236, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "80 epoch, Loss: 0.01875, acc: 27.3202, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "81 epoch, Loss: 0.01869, acc: 27.3208, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "82 epoch, Loss: 0.01844, acc: 27.3177, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "83 epoch, Loss: 0.01824, acc: 27.3132, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "84 epoch, Loss: 0.01810, acc: 27.3132, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "85 epoch, Loss: 0.01830, acc: 27.3139, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "86 epoch, Loss: 0.01833, acc: 27.3144, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "87 epoch, Loss: 0.01890, acc: 27.3225, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "88 epoch, Loss: 0.01838, acc: 27.3138, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "89 epoch, Loss: 0.01823, acc: 27.3122, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "90 epoch, Loss: 0.01799, acc: 27.3095, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "91 epoch, Loss: 0.01779, acc: 27.3084, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "92 epoch, Loss: 0.01764, acc: 27.3047, LR: 0.0010000, Time for cycle: 1.95 sec\n",
      "Data saved \n",
      "\n",
      "93 epoch, Loss: 0.01781, acc: 27.3058, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "94 epoch, Loss: 0.01782, acc: 27.3077, LR: 0.0010000, Time for cycle: 1.89 sec\n",
      "Data saved \n",
      "\n",
      "95 epoch, Loss: 0.01772, acc: 27.3068, LR: 0.0010000, Time for cycle: 2.00 sec\n",
      "Data saved \n",
      "\n",
      "96 epoch, Loss: 0.01738, acc: 27.2987, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "97 epoch, Loss: 0.01723, acc: 27.2971, LR: 0.0010000, Time for cycle: 1.90 sec\n",
      "Data saved \n",
      "\n",
      "98 epoch, Loss: 0.01716, acc: 27.2972, LR: 0.0010000, Time for cycle: 1.94 sec\n",
      "Data saved \n",
      "\n",
      "99 epoch, Loss: 0.01739, acc: 27.2983, LR: 0.0010000, Time for cycle: 1.85 sec\n",
      "Data saved \n",
      "\n",
      "384\n",
      "Model loaded\n",
      "0 epoch, Loss: 0.07935, acc: 28.1168, LR: 0.0010000, Time for cycle: 9.53 sec\n",
      "Data saved \n",
      "\n",
      "1 epoch, Loss: 0.06635, acc: 28.0479, LR: 0.0010000, Time for cycle: 1.86 sec\n",
      "Data saved \n",
      "\n",
      "2 epoch, Loss: 0.06577, acc: 28.0387, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "3 epoch, Loss: 0.06530, acc: 28.0309, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "4 epoch, Loss: 0.06492, acc: 28.0274, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "5 epoch, Loss: 0.06466, acc: 28.0191, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "6 epoch, Loss: 0.06403, acc: 28.0110, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "7 epoch, Loss: 0.06344, acc: 28.0040, LR: 0.0010000, Time for cycle: 1.82 sec\n",
      "Data saved \n",
      "\n",
      "8 epoch, Loss: 0.06291, acc: 27.9947, LR: 0.0010000, Time for cycle: 1.84 sec\n",
      "Data saved \n",
      "\n",
      "9 epoch, Loss: 0.06236, acc: 27.9849, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "10 epoch, Loss: 0.06154, acc: 27.9722, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "11 epoch, Loss: 0.06086, acc: 27.9586, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "12 epoch, Loss: 0.06003, acc: 27.9458, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "13 epoch, Loss: 0.05925, acc: 27.9334, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "14 epoch, Loss: 0.05835, acc: 27.9209, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "15 epoch, Loss: 0.05746, acc: 27.9075, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "16 epoch, Loss: 0.05638, acc: 27.8890, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "17 epoch, Loss: 0.05541, acc: 27.8737, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "18 epoch, Loss: 0.05462, acc: 27.8612, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "19 epoch, Loss: 0.05350, acc: 27.8436, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "20 epoch, Loss: 0.05247, acc: 27.8263, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "21 epoch, Loss: 0.05151, acc: 27.8093, LR: 0.0010000, Time for cycle: 1.88 sec\n",
      "Data saved \n",
      "\n",
      "22 epoch, Loss: 0.05059, acc: 27.7965, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "23 epoch, Loss: 0.04944, acc: 27.7801, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "24 epoch, Loss: 0.04863, acc: 27.7648, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "25 epoch, Loss: 0.04760, acc: 27.7505, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "26 epoch, Loss: 0.04663, acc: 27.7339, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "27 epoch, Loss: 0.04546, acc: 27.7185, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "28 epoch, Loss: 0.04452, acc: 27.7019, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "29 epoch, Loss: 0.04373, acc: 27.6866, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "30 epoch, Loss: 0.04255, acc: 27.6713, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "31 epoch, Loss: 0.04171, acc: 27.6580, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "32 epoch, Loss: 0.04117, acc: 27.6478, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "33 epoch, Loss: 0.04014, acc: 27.6333, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "34 epoch, Loss: 0.03949, acc: 27.6256, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "35 epoch, Loss: 0.03914, acc: 27.6198, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "36 epoch, Loss: 0.03837, acc: 27.6074, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "37 epoch, Loss: 0.03747, acc: 27.5950, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "38 epoch, Loss: 0.03653, acc: 27.5812, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "39 epoch, Loss: 0.03600, acc: 27.5708, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "40 epoch, Loss: 0.03561, acc: 27.5676, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "41 epoch, Loss: 0.03483, acc: 27.5560, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "42 epoch, Loss: 0.03465, acc: 27.5492, LR: 0.0010000, Time for cycle: 1.81 sec\n",
      "Data saved \n",
      "\n",
      "43 epoch, Loss: 0.03402, acc: 27.5442, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "44 epoch, Loss: 0.03362, acc: 27.5376, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "45 epoch, Loss: 0.03302, acc: 27.5286, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "46 epoch, Loss: 0.03271, acc: 27.5242, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "47 epoch, Loss: 0.03239, acc: 27.5210, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "48 epoch, Loss: 0.03194, acc: 27.5122, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "49 epoch, Loss: 0.03123, acc: 27.5026, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "50 epoch, Loss: 0.03140, acc: 27.5046, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "51 epoch, Loss: 0.03085, acc: 27.4986, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "52 epoch, Loss: 0.03025, acc: 27.4893, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "53 epoch, Loss: 0.02999, acc: 27.4854, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "54 epoch, Loss: 0.02962, acc: 27.4783, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "55 epoch, Loss: 0.02946, acc: 27.4773, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "56 epoch, Loss: 0.02940, acc: 27.4762, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "57 epoch, Loss: 0.02895, acc: 27.4700, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "58 epoch, Loss: 0.02858, acc: 27.4668, LR: 0.0010000, Time for cycle: 1.63 sec\n",
      "Data saved \n",
      "\n",
      "59 epoch, Loss: 0.02840, acc: 27.4633, LR: 0.0010000, Time for cycle: 1.92 sec\n",
      "Data saved \n",
      "\n",
      "60 epoch, Loss: 0.02835, acc: 27.4626, LR: 0.0010000, Time for cycle: 2.90 sec\n",
      "Data saved \n",
      "\n",
      "61 epoch, Loss: 0.02789, acc: 27.4560, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "62 epoch, Loss: 0.02770, acc: 27.4540, LR: 0.0010000, Time for cycle: 2.58 sec\n",
      "Data saved \n",
      "\n",
      "63 epoch, Loss: 0.02778, acc: 27.4541, LR: 0.0010000, Time for cycle: 2.44 sec\n",
      "Data saved \n",
      "\n",
      "64 epoch, Loss: 0.02723, acc: 27.4463, LR: 0.0010000, Time for cycle: 1.87 sec\n",
      "Data saved \n",
      "\n",
      "65 epoch, Loss: 0.02689, acc: 27.4388, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "66 epoch, Loss: 0.02715, acc: 27.4454, LR: 0.0010000, Time for cycle: 1.83 sec\n",
      "Data saved \n",
      "\n",
      "67 epoch, Loss: 0.02672, acc: 27.4399, LR: 0.0010000, Time for cycle: 1.95 sec\n",
      "Data saved \n",
      "\n",
      "68 epoch, Loss: 0.02644, acc: 27.4354, LR: 0.0010000, Time for cycle: 2.36 sec\n",
      "Data saved \n",
      "\n",
      "69 epoch, Loss: 0.02608, acc: 27.4300, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "70 epoch, Loss: 0.02616, acc: 27.4303, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "71 epoch, Loss: 0.02587, acc: 27.4275, LR: 0.0010000, Time for cycle: 1.69 sec\n",
      "Data saved \n",
      "\n",
      "72 epoch, Loss: 0.02587, acc: 27.4256, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "73 epoch, Loss: 0.02555, acc: 27.4211, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "74 epoch, Loss: 0.02564, acc: 27.4235, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "75 epoch, Loss: 0.02609, acc: 27.4297, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "76 epoch, Loss: 0.02555, acc: 27.4216, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "77 epoch, Loss: 0.02505, acc: 27.4141, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "78 epoch, Loss: 0.02445, acc: 27.4067, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "79 epoch, Loss: 0.02418, acc: 27.4007, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "80 epoch, Loss: 0.02452, acc: 27.4078, LR: 0.0010000, Time for cycle: 1.78 sec\n",
      "Data saved \n",
      "\n",
      "81 epoch, Loss: 0.02469, acc: 27.4067, LR: 0.0010000, Time for cycle: 1.72 sec\n",
      "Data saved \n",
      "\n",
      "82 epoch, Loss: 0.02433, acc: 27.4038, LR: 0.0010000, Time for cycle: 1.80 sec\n",
      "Data saved \n",
      "\n",
      "83 epoch, Loss: 0.02447, acc: 27.4075, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "84 epoch, Loss: 0.02392, acc: 27.3987, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "85 epoch, Loss: 0.02393, acc: 27.3948, LR: 0.0010000, Time for cycle: 1.66 sec\n",
      "Data saved \n",
      "\n",
      "86 epoch, Loss: 0.02393, acc: 27.3970, LR: 0.0010000, Time for cycle: 1.75 sec\n",
      "Data saved \n",
      "\n",
      "87 epoch, Loss: 0.02363, acc: 27.3961, LR: 0.0010000, Time for cycle: 1.74 sec\n",
      "Data saved \n",
      "\n",
      "88 epoch, Loss: 0.02365, acc: 27.3933, LR: 0.0010000, Time for cycle: 1.64 sec\n",
      "Data saved \n",
      "\n",
      "89 epoch, Loss: 0.02356, acc: 27.3937, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "90 epoch, Loss: 0.02374, acc: 27.3954, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "91 epoch, Loss: 0.02354, acc: 27.3914, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "92 epoch, Loss: 0.02330, acc: 27.3882, LR: 0.0010000, Time for cycle: 1.71 sec\n",
      "Data saved \n",
      "\n",
      "93 epoch, Loss: 0.02304, acc: 27.3859, LR: 0.0010000, Time for cycle: 1.70 sec\n",
      "Data saved \n",
      "\n",
      "94 epoch, Loss: 0.02313, acc: 27.3865, LR: 0.0010000, Time for cycle: 1.77 sec\n",
      "Data saved \n",
      "\n",
      "95 epoch, Loss: 0.02311, acc: 27.3857, LR: 0.0010000, Time for cycle: 1.67 sec\n",
      "Data saved \n",
      "\n",
      "96 epoch, Loss: 0.02287, acc: 27.3825, LR: 0.0010000, Time for cycle: 1.73 sec\n",
      "Data saved \n",
      "\n",
      "97 epoch, Loss: 0.02297, acc: 27.3827, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "98 epoch, Loss: 0.02272, acc: 27.3828, LR: 0.0010000, Time for cycle: 1.76 sec\n",
      "Data saved \n",
      "\n",
      "99 epoch, Loss: 0.02287, acc: 27.3816, LR: 0.0010000, Time for cycle: 1.68 sec\n",
      "Data saved \n",
      "\n",
      "768\n",
      "Model loaded\n",
      "0 epoch, Loss: 0.07722, acc: 28.0903, LR: 0.0010000, Time for cycle: 15.66 sec\n",
      "Data saved \n",
      "\n",
      "1 epoch, Loss: 0.06484, acc: 28.0226, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "2 epoch, Loss: 0.06420, acc: 28.0124, LR: 0.0010000, Time for cycle: 1.98 sec\n",
      "Data saved \n",
      "\n",
      "3 epoch, Loss: 0.06359, acc: 28.0073, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "4 epoch, Loss: 0.06319, acc: 27.9992, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "5 epoch, Loss: 0.06267, acc: 27.9919, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "6 epoch, Loss: 0.06207, acc: 27.9839, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "7 epoch, Loss: 0.06160, acc: 27.9712, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "8 epoch, Loss: 0.06067, acc: 27.9596, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "9 epoch, Loss: 0.05996, acc: 27.9457, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "10 epoch, Loss: 0.05897, acc: 27.9304, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "11 epoch, Loss: 0.05776, acc: 27.9112, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "12 epoch, Loss: 0.05678, acc: 27.8962, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "13 epoch, Loss: 0.05548, acc: 27.8742, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "14 epoch, Loss: 0.05423, acc: 27.8532, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "15 epoch, Loss: 0.05309, acc: 27.8368, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "16 epoch, Loss: 0.05168, acc: 27.8145, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "17 epoch, Loss: 0.05049, acc: 27.7972, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "18 epoch, Loss: 0.04918, acc: 27.7764, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "19 epoch, Loss: 0.04804, acc: 27.7573, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "20 epoch, Loss: 0.04675, acc: 27.7362, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "21 epoch, Loss: 0.04564, acc: 27.7211, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "22 epoch, Loss: 0.04454, acc: 27.7015, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "23 epoch, Loss: 0.04359, acc: 27.6877, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "24 epoch, Loss: 0.04223, acc: 27.6682, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "25 epoch, Loss: 0.04171, acc: 27.6598, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "26 epoch, Loss: 0.04071, acc: 27.6430, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "27 epoch, Loss: 0.03994, acc: 27.6326, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "28 epoch, Loss: 0.03880, acc: 27.6150, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "29 epoch, Loss: 0.03801, acc: 27.6045, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "30 epoch, Loss: 0.03735, acc: 27.5950, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "31 epoch, Loss: 0.03673, acc: 27.5846, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "32 epoch, Loss: 0.03619, acc: 27.5751, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "33 epoch, Loss: 0.03544, acc: 27.5660, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "34 epoch, Loss: 0.03471, acc: 27.5543, LR: 0.0010000, Time for cycle: 2.14 sec\n",
      "Data saved \n",
      "\n",
      "35 epoch, Loss: 0.03390, acc: 27.5451, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "36 epoch, Loss: 0.03330, acc: 27.5359, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "37 epoch, Loss: 0.03304, acc: 27.5324, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "38 epoch, Loss: 0.03221, acc: 27.5202, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "39 epoch, Loss: 0.03176, acc: 27.5117, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "40 epoch, Loss: 0.03140, acc: 27.5065, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "41 epoch, Loss: 0.03080, acc: 27.4977, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "42 epoch, Loss: 0.03051, acc: 27.4949, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "43 epoch, Loss: 0.02991, acc: 27.4857, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "44 epoch, Loss: 0.02973, acc: 27.4828, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "45 epoch, Loss: 0.02924, acc: 27.4755, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "46 epoch, Loss: 0.02885, acc: 27.4699, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "47 epoch, Loss: 0.02862, acc: 27.4686, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "48 epoch, Loss: 0.02820, acc: 27.4601, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "49 epoch, Loss: 0.02780, acc: 27.4537, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "50 epoch, Loss: 0.02737, acc: 27.4484, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "51 epoch, Loss: 0.02755, acc: 27.4517, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "52 epoch, Loss: 0.02721, acc: 27.4450, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "53 epoch, Loss: 0.02687, acc: 27.4400, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "54 epoch, Loss: 0.02653, acc: 27.4353, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "55 epoch, Loss: 0.02626, acc: 27.4318, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "56 epoch, Loss: 0.02568, acc: 27.4231, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "57 epoch, Loss: 0.02507, acc: 27.4136, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "58 epoch, Loss: 0.02512, acc: 27.4177, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "59 epoch, Loss: 0.02517, acc: 27.4157, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "60 epoch, Loss: 0.02486, acc: 27.4110, LR: 0.0010000, Time for cycle: 2.13 sec\n",
      "Data saved \n",
      "\n",
      "61 epoch, Loss: 0.02483, acc: 27.4130, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "62 epoch, Loss: 0.02463, acc: 27.4095, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "63 epoch, Loss: 0.02453, acc: 27.4071, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "64 epoch, Loss: 0.02412, acc: 27.4003, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "65 epoch, Loss: 0.02429, acc: 27.4040, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "66 epoch, Loss: 0.02389, acc: 27.3974, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "67 epoch, Loss: 0.02353, acc: 27.3918, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "68 epoch, Loss: 0.02364, acc: 27.3933, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "69 epoch, Loss: 0.02323, acc: 27.3879, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "70 epoch, Loss: 0.02330, acc: 27.3885, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "71 epoch, Loss: 0.02275, acc: 27.3820, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "72 epoch, Loss: 0.02276, acc: 27.3813, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "73 epoch, Loss: 0.02248, acc: 27.3771, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "74 epoch, Loss: 0.02241, acc: 27.3738, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "75 epoch, Loss: 0.02219, acc: 27.3717, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "76 epoch, Loss: 0.02253, acc: 27.3813, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "77 epoch, Loss: 0.02206, acc: 27.3710, LR: 0.0010000, Time for cycle: 2.30 sec\n",
      "Data saved \n",
      "\n",
      "78 epoch, Loss: 0.02193, acc: 27.3673, LR: 0.0010000, Time for cycle: 2.16 sec\n",
      "Data saved \n",
      "\n",
      "79 epoch, Loss: 0.02151, acc: 27.3627, LR: 0.0010000, Time for cycle: 2.20 sec\n",
      "Data saved \n",
      "\n",
      "80 epoch, Loss: 0.02143, acc: 27.3589, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "81 epoch, Loss: 0.02125, acc: 27.3580, LR: 0.0010000, Time for cycle: 2.20 sec\n",
      "Data saved \n",
      "\n",
      "82 epoch, Loss: 0.02158, acc: 27.3635, LR: 0.0010000, Time for cycle: 2.16 sec\n",
      "Data saved \n",
      "\n",
      "83 epoch, Loss: 0.02180, acc: 27.3668, LR: 0.0010000, Time for cycle: 2.25 sec\n",
      "Data saved \n",
      "\n",
      "84 epoch, Loss: 0.02178, acc: 27.3652, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "85 epoch, Loss: 0.02152, acc: 27.3618, LR: 0.0010000, Time for cycle: 2.28 sec\n",
      "Data saved \n",
      "\n",
      "86 epoch, Loss: 0.02115, acc: 27.3576, LR: 0.0010000, Time for cycle: 2.18 sec\n",
      "Data saved \n",
      "\n",
      "87 epoch, Loss: 0.02094, acc: 27.3545, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "88 epoch, Loss: 0.02040, acc: 27.3466, LR: 0.0010000, Time for cycle: 2.20 sec\n",
      "Data saved \n",
      "\n",
      "89 epoch, Loss: 0.02081, acc: 27.3516, LR: 0.0010000, Time for cycle: 2.24 sec\n",
      "Data saved \n",
      "\n",
      "90 epoch, Loss: 0.02069, acc: 27.3480, LR: 0.0010000, Time for cycle: 2.31 sec\n",
      "Data saved \n",
      "\n",
      "91 epoch, Loss: 0.02014, acc: 27.3422, LR: 0.0010000, Time for cycle: 2.30 sec\n",
      "Data saved \n",
      "\n",
      "92 epoch, Loss: 0.01994, acc: 27.3400, LR: 0.0010000, Time for cycle: 2.18 sec\n",
      "Data saved \n",
      "\n",
      "93 epoch, Loss: 0.02046, acc: 27.3468, LR: 0.0010000, Time for cycle: 2.18 sec\n",
      "Data saved \n",
      "\n",
      "94 epoch, Loss: 0.02054, acc: 27.3474, LR: 0.0010000, Time for cycle: 2.16 sec\n",
      "Data saved \n",
      "\n",
      "95 epoch, Loss: 0.02083, acc: 27.3533, LR: 0.0010000, Time for cycle: 2.13 sec\n",
      "Data saved \n",
      "\n",
      "96 epoch, Loss: 0.02054, acc: 27.3475, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "97 epoch, Loss: 0.01996, acc: 27.3406, LR: 0.0010000, Time for cycle: 2.14 sec\n",
      "Data saved \n",
      "\n",
      "98 epoch, Loss: 0.01997, acc: 27.3383, LR: 0.0010000, Time for cycle: 2.27 sec\n",
      "Data saved \n",
      "\n",
      "99 epoch, Loss: 0.01956, acc: 27.3339, LR: 0.0010000, Time for cycle: 2.17 sec\n",
      "Data saved \n",
      "\n",
      "768\n",
      "Model loaded\n",
      "0 epoch, Loss: 0.07482, acc: 28.0738, LR: 0.0010000, Time for cycle: 18.54 sec\n",
      "Data saved \n",
      "\n",
      "1 epoch, Loss: 0.06468, acc: 28.0180, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "2 epoch, Loss: 0.06392, acc: 28.0092, LR: 0.0010000, Time for cycle: 1.98 sec\n",
      "Data saved \n",
      "\n",
      "3 epoch, Loss: 0.06328, acc: 27.9983, LR: 0.0010000, Time for cycle: 2.01 sec\n",
      "Data saved \n",
      "\n",
      "4 epoch, Loss: 0.06270, acc: 27.9941, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "5 epoch, Loss: 0.06211, acc: 27.9839, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "6 epoch, Loss: 0.06140, acc: 27.9710, LR: 0.0010000, Time for cycle: 2.18 sec\n",
      "Data saved \n",
      "\n",
      "7 epoch, Loss: 0.06051, acc: 27.9603, LR: 0.0010000, Time for cycle: 2.14 sec\n",
      "Data saved \n",
      "\n",
      "8 epoch, Loss: 0.05966, acc: 27.9442, LR: 0.0010000, Time for cycle: 2.18 sec\n",
      "Data saved \n",
      "\n",
      "9 epoch, Loss: 0.05851, acc: 27.9269, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "10 epoch, Loss: 0.05726, acc: 27.9064, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "11 epoch, Loss: 0.05594, acc: 27.8839, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "12 epoch, Loss: 0.05461, acc: 27.8610, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "13 epoch, Loss: 0.05318, acc: 27.8376, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "14 epoch, Loss: 0.05132, acc: 27.8110, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "15 epoch, Loss: 0.04995, acc: 27.7897, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "16 epoch, Loss: 0.04848, acc: 27.7655, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "17 epoch, Loss: 0.04723, acc: 27.7471, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "18 epoch, Loss: 0.04568, acc: 27.7207, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "19 epoch, Loss: 0.04443, acc: 27.7005, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "20 epoch, Loss: 0.04315, acc: 27.6814, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "21 epoch, Loss: 0.04214, acc: 27.6640, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "22 epoch, Loss: 0.04081, acc: 27.6454, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "23 epoch, Loss: 0.04005, acc: 27.6315, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "24 epoch, Loss: 0.03908, acc: 27.6189, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "25 epoch, Loss: 0.03801, acc: 27.6009, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "26 epoch, Loss: 0.03705, acc: 27.5898, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "27 epoch, Loss: 0.03630, acc: 27.5776, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "28 epoch, Loss: 0.03568, acc: 27.5663, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "29 epoch, Loss: 0.03478, acc: 27.5539, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "30 epoch, Loss: 0.03411, acc: 27.5435, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "31 epoch, Loss: 0.03360, acc: 27.5368, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "32 epoch, Loss: 0.03316, acc: 27.5308, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "33 epoch, Loss: 0.03274, acc: 27.5246, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "34 epoch, Loss: 0.03208, acc: 27.5149, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "35 epoch, Loss: 0.03147, acc: 27.5042, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "36 epoch, Loss: 0.03066, acc: 27.4940, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "37 epoch, Loss: 0.03010, acc: 27.4856, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "38 epoch, Loss: 0.02972, acc: 27.4797, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "39 epoch, Loss: 0.02944, acc: 27.4769, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "40 epoch, Loss: 0.02912, acc: 27.4718, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "41 epoch, Loss: 0.02866, acc: 27.4628, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "42 epoch, Loss: 0.02787, acc: 27.4517, LR: 0.0010000, Time for cycle: 2.01 sec\n",
      "Data saved \n",
      "\n",
      "43 epoch, Loss: 0.02761, acc: 27.4492, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "44 epoch, Loss: 0.02733, acc: 27.4436, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "45 epoch, Loss: 0.02709, acc: 27.4415, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "46 epoch, Loss: 0.02691, acc: 27.4398, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "47 epoch, Loss: 0.02637, acc: 27.4322, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "48 epoch, Loss: 0.02598, acc: 27.4274, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "49 epoch, Loss: 0.02566, acc: 27.4191, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "50 epoch, Loss: 0.02547, acc: 27.4202, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "51 epoch, Loss: 0.02522, acc: 27.4160, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "52 epoch, Loss: 0.02520, acc: 27.4148, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "53 epoch, Loss: 0.02493, acc: 27.4104, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "54 epoch, Loss: 0.02477, acc: 27.4093, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "55 epoch, Loss: 0.02452, acc: 27.4048, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "56 epoch, Loss: 0.02438, acc: 27.4034, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "57 epoch, Loss: 0.02388, acc: 27.3944, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "58 epoch, Loss: 0.02405, acc: 27.3987, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "59 epoch, Loss: 0.02381, acc: 27.3945, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "60 epoch, Loss: 0.02333, acc: 27.3869, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "61 epoch, Loss: 0.02316, acc: 27.3878, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "62 epoch, Loss: 0.02326, acc: 27.3864, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "63 epoch, Loss: 0.02301, acc: 27.3836, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "64 epoch, Loss: 0.02259, acc: 27.3777, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "65 epoch, Loss: 0.02248, acc: 27.3734, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "66 epoch, Loss: 0.02275, acc: 27.3791, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "67 epoch, Loss: 0.02233, acc: 27.3734, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "68 epoch, Loss: 0.02246, acc: 27.3756, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "69 epoch, Loss: 0.02212, acc: 27.3694, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "70 epoch, Loss: 0.02185, acc: 27.3661, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "71 epoch, Loss: 0.02164, acc: 27.3640, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "72 epoch, Loss: 0.02172, acc: 27.3629, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "73 epoch, Loss: 0.02183, acc: 27.3647, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "74 epoch, Loss: 0.02151, acc: 27.3625, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "75 epoch, Loss: 0.02098, acc: 27.3532, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "76 epoch, Loss: 0.02112, acc: 27.3566, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "77 epoch, Loss: 0.02107, acc: 27.3550, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "78 epoch, Loss: 0.02119, acc: 27.3559, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "79 epoch, Loss: 0.02104, acc: 27.3555, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "80 epoch, Loss: 0.02083, acc: 27.3517, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "81 epoch, Loss: 0.02106, acc: 27.3535, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "82 epoch, Loss: 0.02107, acc: 27.3558, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "83 epoch, Loss: 0.02066, acc: 27.3484, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "84 epoch, Loss: 0.02058, acc: 27.3473, LR: 0.0010000, Time for cycle: 2.13 sec\n",
      "Data saved \n",
      "\n",
      "85 epoch, Loss: 0.02023, acc: 27.3416, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "86 epoch, Loss: 0.02057, acc: 27.3463, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "87 epoch, Loss: 0.02035, acc: 27.3434, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "88 epoch, Loss: 0.01994, acc: 27.3369, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "89 epoch, Loss: 0.01974, acc: 27.3361, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "90 epoch, Loss: 0.01958, acc: 27.3334, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "91 epoch, Loss: 0.01968, acc: 27.3350, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "92 epoch, Loss: 0.01991, acc: 27.3374, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "93 epoch, Loss: 0.01987, acc: 27.3379, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "94 epoch, Loss: 0.02022, acc: 27.3424, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "95 epoch, Loss: 0.01946, acc: 27.3299, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "96 epoch, Loss: 0.01933, acc: 27.3282, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "97 epoch, Loss: 0.01928, acc: 27.3290, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "98 epoch, Loss: 0.01928, acc: 27.3284, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "99 epoch, Loss: 0.01912, acc: 27.3262, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "768\n",
      "Model loaded\n",
      "0 epoch, Loss: 0.07525, acc: 28.0879, LR: 0.0010000, Time for cycle: 17.96 sec\n",
      "Data saved \n",
      "\n",
      "1 epoch, Loss: 0.06478, acc: 28.0223, LR: 0.0010000, Time for cycle: 1.99 sec\n",
      "Data saved \n",
      "\n",
      "2 epoch, Loss: 0.06425, acc: 28.0127, LR: 0.0010000, Time for cycle: 1.97 sec\n",
      "Data saved \n",
      "\n",
      "3 epoch, Loss: 0.06383, acc: 28.0055, LR: 0.0010000, Time for cycle: 2.00 sec\n",
      "Data saved \n",
      "\n",
      "4 epoch, Loss: 0.06347, acc: 27.9994, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "5 epoch, Loss: 0.06306, acc: 27.9957, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "6 epoch, Loss: 0.06263, acc: 27.9875, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "7 epoch, Loss: 0.06214, acc: 27.9797, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "8 epoch, Loss: 0.06180, acc: 27.9721, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "9 epoch, Loss: 0.06097, acc: 27.9617, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "10 epoch, Loss: 0.06038, acc: 27.9516, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "11 epoch, Loss: 0.05952, acc: 27.9387, LR: 0.0010000, Time for cycle: 2.26 sec\n",
      "Data saved \n",
      "\n",
      "12 epoch, Loss: 0.05879, acc: 27.9263, LR: 0.0010000, Time for cycle: 2.20 sec\n",
      "Data saved \n",
      "\n",
      "13 epoch, Loss: 0.05787, acc: 27.9102, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "14 epoch, Loss: 0.05697, acc: 27.8966, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "15 epoch, Loss: 0.05591, acc: 27.8793, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "16 epoch, Loss: 0.05481, acc: 27.8630, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "17 epoch, Loss: 0.05393, acc: 27.8459, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "18 epoch, Loss: 0.05288, acc: 27.8303, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "19 epoch, Loss: 0.05167, acc: 27.8113, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "20 epoch, Loss: 0.05071, acc: 27.7972, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "21 epoch, Loss: 0.04960, acc: 27.7800, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "22 epoch, Loss: 0.04875, acc: 27.7648, LR: 0.0010000, Time for cycle: 2.01 sec\n",
      "Data saved \n",
      "\n",
      "23 epoch, Loss: 0.04776, acc: 27.7493, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "24 epoch, Loss: 0.04668, acc: 27.7340, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "25 epoch, Loss: 0.04590, acc: 27.7240, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "26 epoch, Loss: 0.04473, acc: 27.7063, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "27 epoch, Loss: 0.04424, acc: 27.6971, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "28 epoch, Loss: 0.04279, acc: 27.6741, LR: 0.0010000, Time for cycle: 2.10 sec\n",
      "Data saved \n",
      "\n",
      "29 epoch, Loss: 0.04218, acc: 27.6652, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "30 epoch, Loss: 0.04123, acc: 27.6508, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "31 epoch, Loss: 0.04068, acc: 27.6423, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "32 epoch, Loss: 0.03969, acc: 27.6293, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "33 epoch, Loss: 0.03900, acc: 27.6180, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "34 epoch, Loss: 0.03832, acc: 27.6092, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "35 epoch, Loss: 0.03772, acc: 27.5995, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "36 epoch, Loss: 0.03707, acc: 27.5882, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "37 epoch, Loss: 0.03628, acc: 27.5784, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "38 epoch, Loss: 0.03564, acc: 27.5656, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "39 epoch, Loss: 0.03544, acc: 27.5620, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "40 epoch, Loss: 0.03474, acc: 27.5539, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "41 epoch, Loss: 0.03438, acc: 27.5492, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "42 epoch, Loss: 0.03366, acc: 27.5387, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "43 epoch, Loss: 0.03339, acc: 27.5344, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "44 epoch, Loss: 0.03278, acc: 27.5232, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "45 epoch, Loss: 0.03225, acc: 27.5156, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "46 epoch, Loss: 0.03202, acc: 27.5132, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "47 epoch, Loss: 0.03190, acc: 27.5110, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "48 epoch, Loss: 0.03135, acc: 27.5035, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "49 epoch, Loss: 0.03105, acc: 27.4978, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "50 epoch, Loss: 0.03042, acc: 27.4905, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n",
      "51 epoch, Loss: 0.03015, acc: 27.4879, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "52 epoch, Loss: 0.02949, acc: 27.4785, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "53 epoch, Loss: 0.02959, acc: 27.4799, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "54 epoch, Loss: 0.02917, acc: 27.4718, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "55 epoch, Loss: 0.02902, acc: 27.4689, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "56 epoch, Loss: 0.02876, acc: 27.4647, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "57 epoch, Loss: 0.02814, acc: 27.4570, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "58 epoch, Loss: 0.02797, acc: 27.4558, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "59 epoch, Loss: 0.02800, acc: 27.4536, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "60 epoch, Loss: 0.02794, acc: 27.4540, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "61 epoch, Loss: 0.02762, acc: 27.4489, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "62 epoch, Loss: 0.02699, acc: 27.4409, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "63 epoch, Loss: 0.02652, acc: 27.4338, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "64 epoch, Loss: 0.02610, acc: 27.4274, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "65 epoch, Loss: 0.02617, acc: 27.4279, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "66 epoch, Loss: 0.02635, acc: 27.4281, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "67 epoch, Loss: 0.02604, acc: 27.4254, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "68 epoch, Loss: 0.02571, acc: 27.4194, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "69 epoch, Loss: 0.02561, acc: 27.4211, LR: 0.0010000, Time for cycle: 2.12 sec\n",
      "Data saved \n",
      "\n",
      "70 epoch, Loss: 0.02549, acc: 27.4178, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "71 epoch, Loss: 0.02503, acc: 27.4107, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "72 epoch, Loss: 0.02462, acc: 27.4055, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "73 epoch, Loss: 0.02449, acc: 27.4036, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "74 epoch, Loss: 0.02427, acc: 27.4011, LR: 0.0010000, Time for cycle: 2.02 sec\n",
      "Data saved \n",
      "\n",
      "75 epoch, Loss: 0.02410, acc: 27.3974, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "76 epoch, Loss: 0.02409, acc: 27.3981, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "77 epoch, Loss: 0.02398, acc: 27.3974, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "78 epoch, Loss: 0.02391, acc: 27.3955, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "79 epoch, Loss: 0.02397, acc: 27.3955, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "80 epoch, Loss: 0.02392, acc: 27.3948, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "81 epoch, Loss: 0.02376, acc: 27.3906, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "82 epoch, Loss: 0.02328, acc: 27.3864, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "83 epoch, Loss: 0.02314, acc: 27.3830, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "84 epoch, Loss: 0.02304, acc: 27.3825, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "85 epoch, Loss: 0.02243, acc: 27.3755, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "86 epoch, Loss: 0.02240, acc: 27.3740, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "87 epoch, Loss: 0.02277, acc: 27.3791, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "88 epoch, Loss: 0.02275, acc: 27.3755, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "89 epoch, Loss: 0.02279, acc: 27.3768, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "90 epoch, Loss: 0.02280, acc: 27.3767, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "91 epoch, Loss: 0.02246, acc: 27.3718, LR: 0.0010000, Time for cycle: 2.03 sec\n",
      "Data saved \n",
      "\n",
      "92 epoch, Loss: 0.02207, acc: 27.3660, LR: 0.0010000, Time for cycle: 2.08 sec\n",
      "Data saved \n",
      "\n",
      "93 epoch, Loss: 0.02198, acc: 27.3684, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "94 epoch, Loss: 0.02190, acc: 27.3634, LR: 0.0010000, Time for cycle: 2.05 sec\n",
      "Data saved \n",
      "\n",
      "95 epoch, Loss: 0.02184, acc: 27.3642, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "96 epoch, Loss: 0.02183, acc: 27.3638, LR: 0.0010000, Time for cycle: 2.06 sec\n",
      "Data saved \n",
      "\n",
      "97 epoch, Loss: 0.02150, acc: 27.3598, LR: 0.0010000, Time for cycle: 2.07 sec\n",
      "Data saved \n",
      "\n",
      "98 epoch, Loss: 0.02157, acc: 27.3608, LR: 0.0010000, Time for cycle: 2.04 sec\n",
      "Data saved \n",
      "\n",
      "99 epoch, Loss: 0.02181, acc: 27.3632, LR: 0.0010000, Time for cycle: 2.09 sec\n",
      "Data saved \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    cm = Net(input_size=dataset[i][0][0].shape[0])\n",
    "    print(dataset[i][0][0].shape[0])\n",
    "    train(False, cm, tnames[i], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/dannu/PycharmProjects/Practice/MoodSongsSearch/src/content/MoodSongs\\modelScaleLessLayers-all-MiniLM-L12-v2.pt\n",
      "c:/Users/dannu/PycharmProjects/Practice/MoodSongsSearch/src/content/MoodSongs\\modelScaleLessLayers-distiluse-base-multilingual-cased-v2.pt\n",
      "c:/Users/dannu/PycharmProjects/Practice/MoodSongsSearch/src/content/MoodSongs\\modelScaleLessLayers-paraphrase-multilingual-MiniLM-L12-v2.pt\n",
      "c:/Users/dannu/PycharmProjects/Practice/MoodSongsSearch/src/content/MoodSongs\\modelScaleLessLayers-all-distilroberta-v1.pt\n",
      "c:/Users/dannu/PycharmProjects/Practice/MoodSongsSearch/src/content/MoodSongs\\modelScaleLessLayers-all-mpnet-base-v2.pt\n",
      "c:/Users/dannu/PycharmProjects/Practice/MoodSongsSearch/src/content/MoodSongs\\modelScaleLessLayers-multi-qa-mpnet-base-dot-v1.pt\n"
     ]
    }
   ],
   "source": [
    "ms = [\n",
    "    None for i in range(len(tnames))\n",
    "]\n",
    "if __name__ == \"__main__\":\n",
    "    for i, name in enumerate(tnames):\n",
    "        # dir = config.ROOT + '/' + config.CHECKPOINT_PATH[0] + name\n",
    "        dir = config.CHECKPOINT_PATH + \"-\" + name\n",
    "        checkpoint = torch.load(dir, map_location=DEVICE)\n",
    "        m = Net(input_size=dataset[i][0][0].shape[0])\n",
    "        m.load_state_dict(checkpoint['model'])\n",
    "        ms[i] = m\n",
    "        # print(os.path.join(config.ROOT + '/' + config.SAVE_DIR, f\"{config.MODEL_NAME}-{name}.pt\"))\n",
    "        # torch.save(m.state_dict(), os.path.join(config.ROOT + '/' + config.SAVE_DIR, f\"{config.MODEL_NAME}-{name}.pt\"))\n",
    "        print(os.path.join(config.SAVE_DIR, f\"{config.MODEL_NAME}-{name}.pt\"))\n",
    "        torch.save(m.state_dict(), os.path.join(config.SAVE_DIR, f\"{config.MODEL_NAME}-{name}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just some testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all-MiniLM-L12-v2...\n",
      "Average distance:  tensor(0.3839, dtype=torch.float64)\n",
      "Testing distiluse-base-multilingual-cased-v2...\n",
      "Average distance:  tensor(0.3916, dtype=torch.float64)\n",
      "Testing paraphrase-multilingual-MiniLM-L12-v2...\n",
      "Average distance:  tensor(0.3962, dtype=torch.float64)\n",
      "Testing all-distilroberta-v1...\n",
      "Average distance:  tensor(0.3921, dtype=torch.float64)\n",
      "Testing all-mpnet-base-v2...\n",
      "Average distance:  tensor(0.3886, dtype=torch.float64)\n",
      "Testing multi-qa-mpnet-base-dot-v1...\n",
      "Average distance:  tensor(0.3997, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    def calc(a, b):\n",
    "        return (a - b) ** 2\n",
    "\n",
    "    def squared_sum(a):\n",
    "        return sum([el **2 for el in a])\n",
    "\n",
    "    def acc(a, b):\n",
    "        assert len(a) == len(b)\n",
    "        # return np.sqrt(np.sum([\n",
    "        #     calc(xa, xb) for xa, xb, in zip(a, b)\n",
    "        # ]))\n",
    "        numerator = sum(xa * xb for xa, xb in zip(a, b))\n",
    "        denominator = squared_sum(a) * squared_sum(b)\n",
    "        return (numerator / float(denominator))\n",
    "\n",
    "\n",
    "    for i in range(len(tnames)):\n",
    "        print(f\"Testing {tnames[i]}...\")\n",
    "        _sum = 0\n",
    "        num = 0\n",
    "        mx = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader[i]:\n",
    "                # print(len(batch))\n",
    "                X, y = batch\n",
    "                output = ms[i](X.view(-1,dataset[i][0][0].shape[0]).to(torch.float32))\n",
    "                for idx, res in enumerate(output):\n",
    "                    _sum += acc(res, y[idx])\n",
    "                    num += 1\n",
    "\n",
    "\n",
    "        print(\"Average distance: \", _sum/num)\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6153846 ,  0.648     ,  0.09090909, -0.09281667,  1.        ,\n",
       "        0.11434303,  0.5539381 ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for dimension 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [65], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m res \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(res, \u001b[39mabs\u001b[39m((m(torch\u001b[39m.\u001b[39;49mfrom_numpy(data[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m])) \u001b[39m-\u001b[39;49m m(torch\u001b[39m.\u001b[39;49mfrom_numpy(data[i][\u001b[39m0\u001b[39;49m])))[\u001b[39m7\u001b[39;49m]))\n\u001b[0;32m      7\u001b[0m     \u001b[39m# print(m(torch.from_numpy(data[i + 1][0])) - m(torch.from_numpy(data[i][0])))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for dimension 0 with size 7"
     ]
    }
   ],
   "source": [
    "data = test_set[:101]\n",
    "import random\n",
    "random.shuffle(data)\n",
    "res = 0\n",
    "for i in range(100):\n",
    "    res = max(res, abs((m(torch.from_numpy(data[i + 1][0])) - m(torch.from_numpy(data[i][0])))[5]))\n",
    "    # print(m(torch.from_numpy(data[i + 1][0])) - m(torch.from_numpy(data[i][0])))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging lyrics and songs with vectors (?? I hope i won't need that in next version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = []\n",
    "\n",
    "for el, vec in zip(song_data, vecs):\n",
    "    song, artist, meta = el[0], el[1], vec[1]\n",
    "    merged.append({'song': song,\n",
    "                   'artist': artist,\n",
    "                   'meta': meta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11559"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(merged)):  # convert to list for serialization\n",
    "    merged[i]['meta'] = list(map(float, merged[i]['meta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"meta+song.json\", 'w') as f:\n",
    "    json.dump(merged, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fba6ffd3d5c7d1161fadb8205652d886bfc0c050f44cc6ebd23b73098b1c521e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
